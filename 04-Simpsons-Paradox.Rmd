# Simpson's Paradox

In 1973, the University of California at Berkeley got worried about being sued for discriminating against women. In their graduate admissions that year, only 35% of female applicants had been admitted, compared to 44% of male applicants.

A professor in the statistics department was recruited to look into it. He found that men and women actually had similar acceptance rates department by department. In fact, women had a higher acceptance rate across most of the larger departments.

```{r echo=FALSE}
library(ggplot2)

df <- data.frame(Applicants = c(825, 560, 325, 417, 191, 373,
                                108, 25, 593, 375, 393, 341),
                 Admitted = c(62, 63, 37, 33, 28, 6,
                              82, 68, 34, 35, 24, 7),
                 Gender = c('Men', 'Men', 'Men', 'Men', 'Men', 'Men',
                           'Women', 'Women', 'Women', 'Women', 'Women', 'Women'),
                 Department = c('A', 'B', 'C', 'D', 'E', 'F',
                               'A', 'B', 'C', 'D', 'E', 'F'))

ggplot(df, aes(x = Department, y = Admitted, fill = Gender)) +
    geom_bar(stat = "identity", position = "dodge") +
    ylab("% Admitted")
```

So how did women end up with a lower acceptance rate overall? Because, it turned out, women had applied more to the more selective departments. Many more women than men had applied to the English department, for example, which admitted only a small fraction of its applicants.

```{r echo=FALSE}
ggplot(df, aes(x = Department, y = Applicants, fill = Gender)) +
    geom_bar(stat = "identity", position = "dodge") +
    ylab("# Applicants")
```

That doesn't mean sexism played no role here necessarily. You might wonder why women and men differed so much in their choices of where to apply, for example. And just because one group has a higher admissions rate doesn't mean they aren't being discriminated against. Harvard once put an admissions cap on Jews because they were being admitted in such large numbers!

But it does mean the initial appearance of discrimination in Berkeley's 1973 admissions was misleading. And it's a great illustration of *Simpson's paradox*, where a trend appears at one level of analysis yet reverses at a more fine-grained level.

In fact, it's even possible for one group to have higher admissions across the board, in every department, and still have a lower admission rate overall. Imagine a fictional case with just two departments. And let's get all the information into a single chart by using width to display the number of applicants:

```{r echo=FALSE}
df <- data.frame(Applicants = c(100, 10, 10, 100),
                 Admitted = c(30, 10, 31, 11),
                 Gender = c('Men', 'Men', 'Women', 'Women'),
                 Department = c('Chemistry', 'Philosophy', 'Chemistry', 'Philosophy'),
                 pos = c(2, 2.825, 2.275, 3.1))

ggplot(df, aes(x = pos, y = Admitted, fill = Gender, width = Applicants / 200)) +
    scale_x_continuous(labels = c('Chemistry', 'Philosophy'), breaks = c(2, 3)) +
    geom_bar(stat = "identity", position = "dodge") +
    xlab("Department") + ylab("% Admitted")
```

The blue bars are taller than their partner red bars, and yet there's much less blue area overall.

So what's the moral? There's a kind of "part-whole" fallacy to watch out for with probabilities. What's true of all the parts isn't necessarily true of the whole. Just because a trend is present in every slice of a population doesn't mean it'll be present in the population overall.


## The Law of Total Probability

There is a right way to do part-whole reasoning with probabilities, though! And it introduces us to a powerful companion principle to Bayes' theorem from the last chapter.

Consider this question: if 20% of all applicants to Chemistry are admitted, and 30% percent of applicants to Philosophy, what's the overall admittance rate across these two departments? Well, it has to be somewhere between 20% and 30%. But what percentage exactly?

It won't necessarily be smack in the middle at 25%. Imagine 100 people apply to Chemistry and only 10 to philosophy. Then 23 people will be admitted out of 110. So the overall rate will be about 21%.

In the reverse situation where 100 people apply to Philosophy and 10 to Chemistry, 32 people will be admitted out of 110, or about 29%.

So the overall rate is closer to the departmental rate of the larger department. And if they're equal sizes, then it will be smack in the middle at 25%.

The Law of Total Probability describes this general pattern. A person's chance of being admitted, $Pr(A)$, is somewhere between their chances of being admitted to Chemistry if they apply there, $Pr(A|C)$, and their chance of being admitted to Philosophy if they apply there, $Pr(A|P)$:

$$ Pr(A|C) < Pr(A) < Pr(P). $$

(I'm assuming they applied to just one department, for simplicity.)

But where exactly will $Pr(A)$ fall in that interval? Well, the more likely it is they applied to Chemistry, the closer it will be to the left end. And the more likely it is they applied to Philosophy, the closer it'll be to the right.

Here's another way to think about the same principle.

Suppose you want to know whether $A$ is true---whether you'll get an A in your next philosophy class, for example. One way to get a handle on that is to break the question down into cases. Maybe the class will be boring, maybe not. We'll use $B$ for boring and $\neg B$ for not boring (the tilde symbol $\neg$ being a common way to symbolize negation).

If the class is boring your chances of getting an A aren't so good, let's suppose. Wheres you're likely to do well if it's not boring. So the more likely it is the class is boring, the lower your chances of getting an A will be.

That kind of reasoning is captured and made precise by:

The Law of Total Probability

:  $$Pr(A) = Pr(A \given B) Pr(B) + Pr(A \given \neg B) Pr(\neg B).$$

In terms of our tree-diagramming technique, the LTP says to add up the final quantities from the $A$-and-$B$ and $A$-and-$\neg B$ branches to get $Pr(A)$.

![](img/LTP-Tree.png)


## Bayes + LTP = Awesome

A big part of why the LTP is interesting is that it makes for a powerful combination with Bayes' theorem. In fact, you often need the LTP to get to the point where you can apply Bayes' theorem.

Remember the problem of base rate neglect? In one example, we imagined a fictional blood test for HIV that always comes up positive when the virus is present. But real medical tests aren't so dependable. They can generate false negatives as well as false positives. And the LTP helps us get the right answer in these more realistic cases.

Here's an example, still fictional, but more realistic:

> About 1 in every 100 people have Weisberg's syndrome (an annoying but mostly harmless disease). There's a blood test that's 90% accurate: in 90% of cases where the disease is present, the test comes up positive, and in 90% of cases where it's absent the test comes up negative.
>
> Suppose a randomly selected person tests positive. What are the chances they have the disease?

Bayes' theorem says that for any hypothesis $H$ and piece of evidence $E$:

Bayes' Theorem

:    $$ Pr(H \given E) = Pr(H)\frac{Pr(E \given H)}{Pr(E)}. $$

We want to calculate $Pr(D \given P)$, the probability of having Weisberg's disease given a positive blood test. So Bayes' theorem says:

$$ Pr(D \given P) = Pr(D) \frac{Pr(P \given D)}{Pr(P)}.$$

So we need the three numbers on the right hand side:

- $Pr(D) = 1/100$, that's the base rate given in the problem.
- $Pr(P \given D) = 90/100$, that's the test-accuracy, also given.
- $Pr(P) = \ldots$ uh-oh, this number isn't given in the description of the problem!

You guessed it, LTP to the rescue! We can calculate the chance of a positive blood test, $Pr(P)$, by breaking it into two cases. What's the chance of a positive test if you really have the disease, and what's the chance if you don't. Then weigh each case according to the chance it's true.

In terms of the LTP, that means we calculate:

$$
\begin{aligned}
  Pr(P) &= Pr(P \given D)Pr(D) + Pr(P \given \neg D)Pr(\neg D)\\
        &= (90/100)(1/100) + (10/100)(99/100)\\
        &= 1,080/10,000\\
        &= 27/250.
\end{aligned}
$$

Where did I get the 99/100 term from, you might be wondering? Well if 1 in 100 people have the disease then 99/100 people don't.

So the chance of a positive blood test is 27/250, which is about 11%. And now we have all three terms we need to apply Bayes' theorem:

$$
\begin{aligned}
Pr(D \given P) &= 1/100 \frac{90/100}{27/250}\\
               &= 0.08333\ldots
\end{aligned}
$$

Once again, the answer is pretty counterintuitive. Despite a test with 90% accuracy, there's still a less than 10% chance you have the disease if you get a positive test. Base rates, don't neglect 'em.

But the new lesson is: Bayes' theorem and the LTP together can solve some problems we wouldn't be able to solve otherwise. In fact, you'll often see Bayes' theorem written with the LTP already built in to the denominator:

$$ Pr(H \given E) = \frac{Pr(E \given H)Pr(H)}{ Pr(E \given H) Pr(H) + Pr(E \given \neg H)Pr(\neg H)}.$$

That's ugly, but really useful if you're doing these calculations on the regular.

We're more interested in the philosophical significance of Bayes' theorem, though. And this messy version obscures a lot of philosophically interesting stuff, as we'll see in the next few chapters. So we'll stick to the simple version.
