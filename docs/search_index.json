[
["the-lottery-paradox.html", "14 The Lottery Paradox", " 14 The Lottery Paradox Oliver: hats How certain does something have to be for you to believe it, 90%? Maybe 95%, or even 99%? Let’s play it safe: suppose the threshold is 99%. Now consider this scenario: You hold one of a hundred lottery tickets. A single winner will be selected at random. Since your ticket’s chance of winning is 99%, you conclude it will lose. The other tickets have the same chance though, so you conclude they will lose too. But that means no ticket will win, which you know is not the case. Did we set the threshold too low? Would boosting it to 99.9% help? No. A higher threshold just needs a larger lottery, with more tickets, for the same puzzle to arise. With 1,000 tickets, each has a 99.9% chance of losing. Should you conclude that they’ll all lose then? "],
["three-principles.html", "14.1 Three Principles", " 14.1 Three Principles The lottery paradox turns on three assumptions, each plausible when considered in isolation. The first is that there is some level of certainty, some threshold of probability, which is sufficient for believability. In other words, there is some number \\(t\\) such that: The Threshold Principle If \\(Pr(A) \\geq t\\), then you should believe \\(A\\). Maybe \\(t = .9\\), or \\(.95\\), or even \\(.99\\). But the lottery paradox shows how any threshold shy of 1 collides with two further principles. The second is that you can combine beliefs you already hold to form new beliefs. We do this all the time, concluding that Cairo is in Africa, for example, because it’s the capital of Egypt, which is an African country. Stripping this idea down to a bare minimum, we have: The Conjunction Principle If it is rational to believe \\(A\\), and it is rational to believe \\(B\\), then it is rational to believe their conjunction, \\(A \\&amp; B\\). In the lottery paradox this leads you to conclude that both tickets #1 and #2 will lose, and #3, and so on up through ticket #100. In other words, all the tickets will lose, even though one must win. Here we meet our last principle, which forbids believing anything that is outright contradictory: No Contradictions It is never rational to believe an outright contradiction, a statement of the form \\(A \\,\\&amp;\\, \\neg A\\). Yet this is precisely where the Threshold and Conjunction Principles have taken us, to the belief that no ticket will win and yet one will. "],
["a-practical-dimension.html", "14.2 A Practical Dimension?", " 14.2 A Practical Dimension? Shouldn’t the certainty needed for belief depend on the context? The more is at stake, the more confidence we’ll demand before accepting a conclusion. Yet the Threshold Principle makes no mention of a contextual element. There’s no allowance that \\(t\\) might vary depending on what’s at stake. Could that be what’s missing from our analysis? No, as we can see a few different ways. One is to imagine the lottery having extremely low stakes. Maybe the prize is a paltry $1. Or maybe you don’t hold one of the tickets yourself, you’re just idly speculating about a lottery others are participating in. There may well be a pragmatic element to acceptance. But this doesn’t help us solve the lottery paradox. Wherever the context fixes the threshold, a large enough lottery will put each ticket’s chances of losing above that contextually determined threshold. "],
["conjunctivitis.html", "14.3 Conjunctivitis", " 14.3 Conjunctivitis Henry Kyburg, who made the lottery paradox famous in the 1960s, blamed the Conjunction Principle. You should believe of each individual ticket that it will lose, said Kyburg. But you can’t conclude further that they’ll all lose, considered as a unit. Although the Conjunction Principle may seem tempting, the lottery example shows it to be pathological—the temptation to embrace it is an illness we must combat, “conjunctivitis”. One thing to consider about Kyburg’s solution is that, even without the Conjunction Principle, your beliefs are still inconsistent as a collection. There’s no one contradictory thing you believe. But your world-view, taken as a whole, is impossible. It just can’t be that each individual ticket loses and yet one wins. Is this something we just have to live with? We’ll come back to this in the next chapter, when we meet the preface paradox. A second worry about Kyburg’s solution is that it puts the concept of belief in peril. What’s the point of believing something if you can’t count on it in logical reasoning? Surely it’s okay to combine your beliefs sometimes, like when you conclude that Cairo is in Africa because it’s the capital of Egypt, which is an African country. So when is it okay to combine beliefs, and when not? The obvious answer is: it’s okay when the combined belief is still highly probable. But if probability is the ultimate decider in what to believe, then what’s the point of believing? What you believe doesn’t inform what other beliefs you’ll adopt; that all depends on probabilities. And your decisions about what to do will also be determined by the probabilities, via the expected utility rule. But if accepting something as true doesn’t affect what else you accept, or what you choose to do, what effects does it have? What role does belief play in our mental lives, if not to guide our reasoning about what to think and do? "],
["degrees-of-belief.html", "14.4 Degrees of Belief", " 14.4 Degrees of Belief In the 1960s and ’70s, Richard Jeffrey embraced this line of thinking and followed it all the way it to its logical conclusion. The whole idea of belief is pointless, he thought, at least the way it’s traditionally conceived. Probability really is the ultimate arbiter of what to think and do, so that must be all there is to belief. We may be used to thinking and talking about beliefs in on/off terms. But really, belief comes in degrees. We might say that you believe \\(2+2 = 4\\), and that Bill Gates is the richest person alive. But one of these beliefs is much stronger than the other. You are more confident that \\(2+2=4\\) than that Bill Gates is the richest living person. So we should replace the concept of “belief” with “degrees of belief”. The idea that belief is a discrete, yes/no thing is just a naive bit of outmoded psychology, Jeffrey said. Instead, belief comes on a continuum from no belief at all (0) to perfect certainty (1). The fundamental requirement of consistent belief isn’t avoiding contradictions, on this view. It’s having degrees of belief that obey the laws of probability. If you’re 70% confident it will rain today, you should be 30% confident it won’t. And in the lottery paradox, your degrees of belief do obey the laws of probability. You are 99% certain that ticket #1 will lose, and likewise for ticket #2, or any other ticket. And this is perfectly consistent with the laws of probability. After all, if we repeated this lottery over and over again every day for many years, each ticket would lose 99% of the time. A concern for Jeffrey’s view is whether it is psychologically realistic. Is it really true that humans never take a conclusion as given? Are we really always hedging under the hood, working with the high probability that something is true rather than just the flat assumption that it is true? For my part, I’m skeptical. It’s not just that it doesn’t feel like I’m working probabilistically when I look up and see that the sun is out. Introspection about the workings of the mind is a notoriously unreliable way of doing serious psychology, after all. It’s also that I see disproof of Jeffrey’s view when I look at the models psychologists have actually developed of human reasoning. These models often seem to include reasoning process based on yes/no assumptions. But this is a live controversy, and the psychological study of human reasoning is still in its early stages. So, skeptical as I am, I think it’s still too early to say categorically that Jeffrey was wrong. (An irony I hope he would have appreciated.) "],
["mind-your-sources.html", "14.5 Mind Your Sources", " 14.5 Mind Your Sources A different angle on the lottery paradox challenges The Threshold Principle instead. Being highly probable isn’t by itself enough to make something believable, say many philosophers. Other factors matter too. What other factors? We can’t review all the proposals out there, but here is one representative, due to Dana Nelkin. Nelkin points out that your basis for thinking your lottery ticket will lose is purely statistical. And this sets it apart from mundane cases where belief is reasonable. If you see a car accident while walking to work, your belief that there was an accident is based on direct, visual observation. Or, if a friend tells you they saw an accident, your belief is based on testimony. Beliefs based on direct observation, or testimony, or other legitimate grounds, have something important in common, according to Nelkin. There is a connection between the event your belief is about, and the belief you form. The accident causes your belief; it explains why you formed that belief. But in the lottery paradox, your belief that (say) ticket #42 will lose isn’t caused or explained by that ticket losing. The drawing may not even have happened yet (and future events can’t cause past events!). So, Nelkin says, you should believe ticket #42 will lose, even though it’s highly probable. The problem now is that some beliefs about future events are reasonable. Suppose I turn my stove on and go watch TV while I wait for it to heat up. I expect my stove to be hot in five minutes’ time, but that future event doesn’t cause or explain why I believe it will happen. Rather, a common cause explains both my belief and the future hotness: me turning the stove on. So too in the lottery paradox, the arrangements made at the lottery commission’s office are a common cause. Those arrangements explain why I believe ticket #42 will lose. And when that ticket does lose, those same arrangements explain why it did (it was just one of a hundred, so it was extremely likely to do so). Still, many philosophers have held on to the idea that there’s something distinctive about “purely statistical” evidence. It may be hard to say what separates the high probability in the lottery paradox from more mundane grounds for a belief, like observation and testimony. But there does seem to be something odd about believing that a given lottery ticket will lose. One way to get at this oddity is to consider what you would say after the drawing, where ticket #67 is selected as the winner. If someone claimed to know all along that ticket #42 would lose, you might retort that they couldn’t have known that. “You had identical reasons for thinking ticket #67 would lose,” you might say, “and yet it won.” For whatever reason, it seems you can’t know ticket #42 will lose, even if you end up being right that it does. And this seems to speak against believing it’ll lose. Perhaps because to believe something just is to take yourself to know it, as some philosophers have held. "],
["taking-stock.html", "14.6 Taking Stock", " 14.6 Taking Stock So what’s the moral of the lottery paradox? We’ve learned that there’s a conflict between some very elementary and appealing ideas. If we want a threshold of probability, beyond which we can take a conclusion as settled, then we have to abandon the idea that “settled” really means settled. We can’t just take the conclusions we’ve drawn and combine them freely. Otherwise, we’re liable to reach improbable conclusions, even contradictory ones. What we should do with that lesson, however, isn’t so clear just yet. Does that mean there’s no such threshold? Or does it mean that there’s really no such thing as a “settled” belief? Looking at some more paradox in this neighbourhood may help us get clearer on these matters. "]
]
